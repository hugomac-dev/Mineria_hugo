{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Axel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np    \n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'algunas',\n",
       " 'algunos',\n",
       " 'ante',\n",
       " 'antes',\n",
       " 'como',\n",
       " 'con',\n",
       " 'contra',\n",
       " 'cual',\n",
       " 'cuando',\n",
       " 'de',\n",
       " 'del',\n",
       " 'desde',\n",
       " 'donde',\n",
       " 'durante',\n",
       " 'e',\n",
       " 'el',\n",
       " 'ella',\n",
       " 'ellas',\n",
       " 'ellos',\n",
       " 'en',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'eras',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'esa',\n",
       " 'esas',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'esos',\n",
       " 'esta',\n",
       " 'estaba',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estabas',\n",
       " 'estad',\n",
       " 'estada',\n",
       " 'estadas',\n",
       " 'estado',\n",
       " 'estados',\n",
       " 'estamos',\n",
       " 'estando',\n",
       " 'estar',\n",
       " 'estaremos',\n",
       " 'estará',\n",
       " 'estarán',\n",
       " 'estarás',\n",
       " 'estaré',\n",
       " 'estaréis',\n",
       " 'estaría',\n",
       " 'estaríais',\n",
       " 'estaríamos',\n",
       " 'estarían',\n",
       " 'estarías',\n",
       " 'estas',\n",
       " 'este',\n",
       " 'estemos',\n",
       " 'esto',\n",
       " 'estos',\n",
       " 'estoy',\n",
       " 'estuve',\n",
       " 'estuviera',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuvieras',\n",
       " 'estuvieron',\n",
       " 'estuviese',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estuvieses',\n",
       " 'estuvimos',\n",
       " 'estuviste',\n",
       " 'estuvisteis',\n",
       " 'estuviéramos',\n",
       " 'estuviésemos',\n",
       " 'estuvo',\n",
       " 'está',\n",
       " 'estábamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'estás',\n",
       " 'esté',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estés',\n",
       " 'fue',\n",
       " 'fuera',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fueras',\n",
       " 'fueron',\n",
       " 'fuese',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'fueses',\n",
       " 'fui',\n",
       " 'fuimos',\n",
       " 'fuiste',\n",
       " 'fuisteis',\n",
       " 'fuéramos',\n",
       " 'fuésemos',\n",
       " 'ha',\n",
       " 'habida',\n",
       " 'habidas',\n",
       " 'habido',\n",
       " 'habidos',\n",
       " 'habiendo',\n",
       " 'habremos',\n",
       " 'habrá',\n",
       " 'habrán',\n",
       " 'habrás',\n",
       " 'habré',\n",
       " 'habréis',\n",
       " 'habría',\n",
       " 'habríais',\n",
       " 'habríamos',\n",
       " 'habrían',\n",
       " 'habrías',\n",
       " 'habéis',\n",
       " 'había',\n",
       " 'habíais',\n",
       " 'habíamos',\n",
       " 'habían',\n",
       " 'habías',\n",
       " 'han',\n",
       " 'has',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'haya',\n",
       " 'hayamos',\n",
       " 'hayan',\n",
       " 'hayas',\n",
       " 'hayáis',\n",
       " 'he',\n",
       " 'hemos',\n",
       " 'hube',\n",
       " 'hubiera',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubieras',\n",
       " 'hubieron',\n",
       " 'hubiese',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'hubieses',\n",
       " 'hubimos',\n",
       " 'hubiste',\n",
       " 'hubisteis',\n",
       " 'hubiéramos',\n",
       " 'hubiésemos',\n",
       " 'hubo',\n",
       " 'la',\n",
       " 'las',\n",
       " 'le',\n",
       " 'les',\n",
       " 'lo',\n",
       " 'los',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'mucho',\n",
       " 'muchos',\n",
       " 'muy',\n",
       " 'más',\n",
       " 'mí',\n",
       " 'mía',\n",
       " 'mías',\n",
       " 'mío',\n",
       " 'míos',\n",
       " 'nada',\n",
       " 'ni',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nosotras',\n",
       " 'nosotros',\n",
       " 'nuestra',\n",
       " 'nuestras',\n",
       " 'nuestro',\n",
       " 'nuestros',\n",
       " 'o',\n",
       " 'os',\n",
       " 'otra',\n",
       " 'otras',\n",
       " 'otro',\n",
       " 'otros',\n",
       " 'para',\n",
       " 'pero',\n",
       " 'poco',\n",
       " 'por',\n",
       " 'porque',\n",
       " 'que',\n",
       " 'quien',\n",
       " 'quienes',\n",
       " 'qué',\n",
       " 'se',\n",
       " 'sea',\n",
       " 'seamos',\n",
       " 'sean',\n",
       " 'seas',\n",
       " 'sentid',\n",
       " 'sentida',\n",
       " 'sentidas',\n",
       " 'sentido',\n",
       " 'sentidos',\n",
       " 'seremos',\n",
       " 'será',\n",
       " 'serán',\n",
       " 'serás',\n",
       " 'seré',\n",
       " 'seréis',\n",
       " 'sería',\n",
       " 'seríais',\n",
       " 'seríamos',\n",
       " 'serían',\n",
       " 'serías',\n",
       " 'seáis',\n",
       " 'siente',\n",
       " 'sin',\n",
       " 'sintiendo',\n",
       " 'sobre',\n",
       " 'sois',\n",
       " 'somos',\n",
       " 'son',\n",
       " 'soy',\n",
       " 'su',\n",
       " 'sus',\n",
       " 'suya',\n",
       " 'suyas',\n",
       " 'suyo',\n",
       " 'suyos',\n",
       " 'sí',\n",
       " 'también',\n",
       " 'tanto',\n",
       " 'te',\n",
       " 'tendremos',\n",
       " 'tendrá',\n",
       " 'tendrán',\n",
       " 'tendrás',\n",
       " 'tendré',\n",
       " 'tendréis',\n",
       " 'tendría',\n",
       " 'tendríais',\n",
       " 'tendríamos',\n",
       " 'tendrían',\n",
       " 'tendrías',\n",
       " 'tened',\n",
       " 'tenemos',\n",
       " 'tenga',\n",
       " 'tengamos',\n",
       " 'tengan',\n",
       " 'tengas',\n",
       " 'tengo',\n",
       " 'tengáis',\n",
       " 'tenida',\n",
       " 'tenidas',\n",
       " 'tenido',\n",
       " 'tenidos',\n",
       " 'teniendo',\n",
       " 'tenéis',\n",
       " 'tenía',\n",
       " 'teníais',\n",
       " 'teníamos',\n",
       " 'tenían',\n",
       " 'tenías',\n",
       " 'ti',\n",
       " 'tiene',\n",
       " 'tienen',\n",
       " 'tienes',\n",
       " 'todo',\n",
       " 'todos',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'tuve',\n",
       " 'tuviera',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuvieras',\n",
       " 'tuvieron',\n",
       " 'tuviese',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'tuvieses',\n",
       " 'tuvimos',\n",
       " 'tuviste',\n",
       " 'tuvisteis',\n",
       " 'tuviéramos',\n",
       " 'tuviésemos',\n",
       " 'tuvo',\n",
       " 'tuya',\n",
       " 'tuyas',\n",
       " 'tuyo',\n",
       " 'tuyos',\n",
       " 'tú',\n",
       " 'un',\n",
       " 'una',\n",
       " 'uno',\n",
       " 'unos',\n",
       " 'vosotras',\n",
       " 'vosotros',\n",
       " 'vuestra',\n",
       " 'vuestras',\n",
       " 'vuestro',\n",
       " 'vuestros',\n",
       " 'y',\n",
       " 'ya',\n",
       " 'yo',\n",
       " 'él',\n",
       " 'éramos'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('spanish'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Párrafo 1\n",
    "text_01 = \"Se dispara el coronavirus: la cifra de muertos aumenta 242 en la provincia de Hubei, mientras que la cifra mundial de muertes por coronavirus aumenta a 1.357\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Párrafo 2\n",
    "text_02 =\"The 2020 #ChineseGP will be postponed due to the coronavirus outbreak F1 and the FIA have accepted a request from the promoter to postpone the event We will continue to monitor the situation and assess potential alternative dates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Párrafo 3\n",
    "text_03 =\"Crea @UNAM_MX Licenciatura en Ingeniería Aeroespacial Se impartirá en la Facultad de Ingeniería, en Ciudad Universitaria, donde los alumnos deberán cursar 10 semestres y cubrir 450 créditos.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Párrafo 4\n",
    "text_04 =\"Samsung Galaxy Z Flip cuenta con una pantalla protegida por vidrio ultra fino, tiene una pequeña pantalla en el exterior que muestra la hora o quién te llama y lo más importante: permite hacer selfies sin tocar ningún botón.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parrafo 5\n",
    "text_05 =\"Llegó el 2020 y nos encontramos con una serie de estrenos que nos harán iniciar a lo grande. Sin lugar a dudas, el regreso de Cloud, Tifa y Aerith en Final Fantasy VII Remake, no se trata solamente de uno de los juegos más esperados del año, sino más bien de la década\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dispara', 'coronavirus', 'cifra', 'muertos', 'aumenta', '242', 'provincia', 'hubei', 'mientras', 'cifra', 'mundial', 'muertes', 'coronavirus', 'aumenta', '1', '357']\n"
     ]
    }
   ],
   "source": [
    "text_01_tokens = tokenizer.tokenize(text_01.lower()) #tokenizar y quitar signos de puntuación\n",
    "#print(text_01_tokens)\n",
    "\n",
    "text_01_tokens_wout_stopwords = []\n",
    "\n",
    "for word in text_01_tokens:\n",
    "    if word not in stopwords.words('spanish'): text_01_tokens_wout_stopwords.append(word)\n",
    "\n",
    "print(text_01_tokens_wout_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020', 'chinesegp', 'postponed', 'due', 'coronavirus', 'outbreak', 'f1', 'fia', 'accepted', 'request', 'promoter', 'postpone', 'event', 'continue', 'monitor', 'situation', 'assess', 'potential', 'alternative', 'dates']\n"
     ]
    }
   ],
   "source": [
    "text_02_tokens = tokenizer.tokenize(text_02.lower()) #tokenizar y quitar signos de puntuación\n",
    "#print(text_02_tokens)\n",
    "\n",
    "text_02_tokens_wout_stopwords = []\n",
    "\n",
    "for word in text_02_tokens:\n",
    "    if word not in stopwords.words('english'): text_02_tokens_wout_stopwords.append(word)\n",
    "\n",
    "print(text_02_tokens_wout_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crea', 'unam_mx', 'licenciatura', 'ingeniería', 'aeroespacial', 'impartirá', 'facultad', 'ingeniería', 'ciudad', 'universitaria', 'alumnos', 'deberán', 'cursar', '10', 'semestres', 'cubrir', '450', 'créditos']\n"
     ]
    }
   ],
   "source": [
    "text_03_tokens = tokenizer.tokenize(text_03.lower()) \n",
    "#print(text_03_tokens)\n",
    "\n",
    "text_03_tokens_wout_stopwords = []\n",
    "\n",
    "for word in text_03_tokens:\n",
    "    if word not in stopwords.words('spanish'): text_03_tokens_wout_stopwords.append(word)\n",
    "\n",
    "print(text_03_tokens_wout_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crea', 'unam_mx', 'licenciatura', 'ingeniería', 'aeroespacial', 'impartirá', 'facultad', 'ingeniería', 'ciudad', 'universitaria', 'alumnos', 'deberán', 'cursar', '10', 'semestres', 'cubrir', '450', 'créditos']\n"
     ]
    }
   ],
   "source": [
    "text_04_tokens = tokenizer.tokenize(text_03.lower()) \n",
    "#print(text_04_tokens)\n",
    "\n",
    "text_04_tokens_wout_stopwords = []\n",
    "\n",
    "for word in text_04_tokens:\n",
    "    if word not in stopwords.words('spanish'): text_04_tokens_wout_stopwords.append(word)\n",
    "\n",
    "print(text_04_tokens_wout_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llegó', '2020', 'encontramos', 'serie', 'estrenos', 'harán', 'iniciar', 'grande', 'lugar', 'dudas', 'regreso', 'cloud', 'tifa', 'aerith', 'final', 'fantasy', 'vii', 'remake', 'trata', 'solamente', 'juegos', 'esperados', 'año', 'sino', 'bien', 'década']\n"
     ]
    }
   ],
   "source": [
    "text_05_tokens = tokenizer.tokenize(text_05.lower()) \n",
    "#print(text_05_tokens)\n",
    "\n",
    "text_05_tokens_wout_stopwords = []\n",
    "\n",
    "for word in text_05_tokens:\n",
    "    if word not in stopwords.words('spanish'): text_05_tokens_wout_stopwords.append(word)\n",
    "\n",
    "print(text_05_tokens_wout_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "20\n",
      "18\n",
      "18\n",
      "26\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(text_01_tokens_wout_stopwords))\n",
    "print(len(text_02_tokens_wout_stopwords))\n",
    "print(len(text_03_tokens_wout_stopwords))\n",
    "print(len(text_04_tokens_wout_stopwords))\n",
    "print(len(text_05_tokens_wout_stopwords))\n",
    "print(len(text_01_tokens_wout_stopwords) + len(text_02_tokens_wout_stopwords) + len(text_03_tokens_wout_stopwords)+len(text_04_tokens_wout_stopwords)+len(text_05_tokens_wout_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_texts = {\"text_01\": text_01_tokens_wout_stopwords, \n",
    "              \"text_02\": text_02_tokens_wout_stopwords, \n",
    "              \"text_03\": text_03_tokens_wout_stopwords,\n",
    "              \"text_04\": text_04_tokens_wout_stopwords,\n",
    "              \"text_05\": text_05_tokens_wout_stopwords,}\n",
    "#dicc_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dispara': 1,\n",
       " 'coronavirus': 3,\n",
       " 'cifra': 2,\n",
       " 'muertos': 1,\n",
       " 'aumenta': 2,\n",
       " '242': 1,\n",
       " 'provincia': 1,\n",
       " 'hubei': 1,\n",
       " 'mientras': 1,\n",
       " 'mundial': 1,\n",
       " 'muertes': 1,\n",
       " '1': 1,\n",
       " '357': 1,\n",
       " '2020': 2,\n",
       " 'chinesegp': 1,\n",
       " 'postponed': 1,\n",
       " 'due': 1,\n",
       " 'outbreak': 1,\n",
       " 'f1': 1,\n",
       " 'fia': 1,\n",
       " 'accepted': 1,\n",
       " 'request': 1,\n",
       " 'promoter': 1,\n",
       " 'postpone': 1,\n",
       " 'event': 1,\n",
       " 'continue': 1,\n",
       " 'monitor': 1,\n",
       " 'situation': 1,\n",
       " 'assess': 1,\n",
       " 'potential': 1,\n",
       " 'alternative': 1,\n",
       " 'dates': 1,\n",
       " 'crea': 2,\n",
       " 'unam_mx': 2,\n",
       " 'licenciatura': 2,\n",
       " 'ingeniería': 4,\n",
       " 'aeroespacial': 2,\n",
       " 'impartirá': 2,\n",
       " 'facultad': 2,\n",
       " 'ciudad': 2,\n",
       " 'universitaria': 2,\n",
       " 'alumnos': 2,\n",
       " 'deberán': 2,\n",
       " 'cursar': 2,\n",
       " '10': 2,\n",
       " 'semestres': 2,\n",
       " 'cubrir': 2,\n",
       " '450': 2,\n",
       " 'créditos': 2,\n",
       " 'llegó': 1,\n",
       " 'encontramos': 1,\n",
       " 'serie': 1,\n",
       " 'estrenos': 1,\n",
       " 'harán': 1,\n",
       " 'iniciar': 1,\n",
       " 'grande': 1,\n",
       " 'lugar': 1,\n",
       " 'dudas': 1,\n",
       " 'regreso': 1,\n",
       " 'cloud': 1,\n",
       " 'tifa': 1,\n",
       " 'aerith': 1,\n",
       " 'final': 1,\n",
       " 'fantasy': 1,\n",
       " 'vii': 1,\n",
       " 'remake': 1,\n",
       " 'trata': 1,\n",
       " 'solamente': 1,\n",
       " 'juegos': 1,\n",
       " 'esperados': 1,\n",
       " 'año': 1,\n",
       " 'sino': 1,\n",
       " 'bien': 1,\n",
       " 'década': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc_termns = {}\n",
    "\n",
    "for text in dicc_texts:\n",
    "    for word in dicc_texts[text]:\n",
    "        \n",
    "#        print(\"EVALUAR:\", word, \"EN\", text)\n",
    "        \n",
    "        if(word in dicc_termns):#incrementar palabras al diccionario\n",
    "            dicc_termns[word] = dicc_termns[word] + 1\n",
    "            \n",
    "#            print(word, \"IN\", \"dicc_termns\")\n",
    "            \n",
    "        elif(word not in dicc_termns):#agregar palabras al diccionario        \n",
    "            dicc_termns[word] = 1\n",
    "            \n",
    "#            print(word, \"NOT IN\", \"dicc_termns\")            \n",
    "\n",
    "print(len(dicc_termns))\n",
    "dicc_termns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "matriz termino documento (binaria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((len(dicc_texts), len(dicc_termns))) # Pre-allocate matrix\n",
    "#matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispara IN text_01\n",
      "se agregó:  1.0 en:  0 0\n",
      "dispara NOT IN text_02\n",
      "se agregó:  0.0 en:  1 0\n",
      "dispara NOT IN text_03\n",
      "se agregó:  0.0 en:  2 0\n",
      "dispara NOT IN text_04\n",
      "se agregó:  0.0 en:  3 0\n",
      "dispara NOT IN text_05\n",
      "se agregó:  0.0 en:  4 0\n",
      "coronavirus IN text_01\n",
      "se agregó:  1.0 en:  0 1\n",
      "coronavirus IN text_02\n",
      "se agregó:  1.0 en:  1 1\n",
      "coronavirus NOT IN text_03\n",
      "se agregó:  0.0 en:  2 1\n",
      "coronavirus NOT IN text_04\n",
      "se agregó:  0.0 en:  3 1\n",
      "coronavirus NOT IN text_05\n",
      "se agregó:  0.0 en:  4 1\n",
      "cifra IN text_01\n",
      "se agregó:  1.0 en:  0 2\n",
      "cifra NOT IN text_02\n",
      "se agregó:  0.0 en:  1 2\n",
      "cifra NOT IN text_03\n",
      "se agregó:  0.0 en:  2 2\n",
      "cifra NOT IN text_04\n",
      "se agregó:  0.0 en:  3 2\n",
      "cifra NOT IN text_05\n",
      "se agregó:  0.0 en:  4 2\n",
      "muertos IN text_01\n",
      "se agregó:  1.0 en:  0 3\n",
      "muertos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 3\n",
      "muertos NOT IN text_03\n",
      "se agregó:  0.0 en:  2 3\n",
      "muertos NOT IN text_04\n",
      "se agregó:  0.0 en:  3 3\n",
      "muertos NOT IN text_05\n",
      "se agregó:  0.0 en:  4 3\n",
      "aumenta IN text_01\n",
      "se agregó:  1.0 en:  0 4\n",
      "aumenta NOT IN text_02\n",
      "se agregó:  0.0 en:  1 4\n",
      "aumenta NOT IN text_03\n",
      "se agregó:  0.0 en:  2 4\n",
      "aumenta NOT IN text_04\n",
      "se agregó:  0.0 en:  3 4\n",
      "aumenta NOT IN text_05\n",
      "se agregó:  0.0 en:  4 4\n",
      "242 IN text_01\n",
      "se agregó:  1.0 en:  0 5\n",
      "242 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 5\n",
      "242 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 5\n",
      "242 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 5\n",
      "242 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 5\n",
      "provincia IN text_01\n",
      "se agregó:  1.0 en:  0 6\n",
      "provincia NOT IN text_02\n",
      "se agregó:  0.0 en:  1 6\n",
      "provincia NOT IN text_03\n",
      "se agregó:  0.0 en:  2 6\n",
      "provincia NOT IN text_04\n",
      "se agregó:  0.0 en:  3 6\n",
      "provincia NOT IN text_05\n",
      "se agregó:  0.0 en:  4 6\n",
      "hubei IN text_01\n",
      "se agregó:  1.0 en:  0 7\n",
      "hubei NOT IN text_02\n",
      "se agregó:  0.0 en:  1 7\n",
      "hubei NOT IN text_03\n",
      "se agregó:  0.0 en:  2 7\n",
      "hubei NOT IN text_04\n",
      "se agregó:  0.0 en:  3 7\n",
      "hubei NOT IN text_05\n",
      "se agregó:  0.0 en:  4 7\n",
      "mientras IN text_01\n",
      "se agregó:  1.0 en:  0 8\n",
      "mientras NOT IN text_02\n",
      "se agregó:  0.0 en:  1 8\n",
      "mientras NOT IN text_03\n",
      "se agregó:  0.0 en:  2 8\n",
      "mientras NOT IN text_04\n",
      "se agregó:  0.0 en:  3 8\n",
      "mientras NOT IN text_05\n",
      "se agregó:  0.0 en:  4 8\n",
      "mundial IN text_01\n",
      "se agregó:  1.0 en:  0 9\n",
      "mundial NOT IN text_02\n",
      "se agregó:  0.0 en:  1 9\n",
      "mundial NOT IN text_03\n",
      "se agregó:  0.0 en:  2 9\n",
      "mundial NOT IN text_04\n",
      "se agregó:  0.0 en:  3 9\n",
      "mundial NOT IN text_05\n",
      "se agregó:  0.0 en:  4 9\n",
      "muertes IN text_01\n",
      "se agregó:  1.0 en:  0 10\n",
      "muertes NOT IN text_02\n",
      "se agregó:  0.0 en:  1 10\n",
      "muertes NOT IN text_03\n",
      "se agregó:  0.0 en:  2 10\n",
      "muertes NOT IN text_04\n",
      "se agregó:  0.0 en:  3 10\n",
      "muertes NOT IN text_05\n",
      "se agregó:  0.0 en:  4 10\n",
      "1 IN text_01\n",
      "se agregó:  1.0 en:  0 11\n",
      "1 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 11\n",
      "1 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 11\n",
      "1 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 11\n",
      "1 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 11\n",
      "357 IN text_01\n",
      "se agregó:  1.0 en:  0 12\n",
      "357 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 12\n",
      "357 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 12\n",
      "357 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 12\n",
      "357 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 12\n",
      "2020 NOT IN text_01\n",
      "se agregó:  0.0 en:  0 13\n",
      "2020 IN text_02\n",
      "se agregó:  1.0 en:  1 13\n",
      "2020 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 13\n",
      "2020 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 13\n",
      "2020 IN text_05\n",
      "se agregó:  1.0 en:  4 13\n",
      "chinesegp NOT IN text_01\n",
      "se agregó:  0.0 en:  0 14\n",
      "chinesegp IN text_02\n",
      "se agregó:  1.0 en:  1 14\n",
      "chinesegp NOT IN text_03\n",
      "se agregó:  0.0 en:  2 14\n",
      "chinesegp NOT IN text_04\n",
      "se agregó:  0.0 en:  3 14\n",
      "chinesegp NOT IN text_05\n",
      "se agregó:  0.0 en:  4 14\n",
      "postponed NOT IN text_01\n",
      "se agregó:  0.0 en:  0 15\n",
      "postponed IN text_02\n",
      "se agregó:  1.0 en:  1 15\n",
      "postponed NOT IN text_03\n",
      "se agregó:  0.0 en:  2 15\n",
      "postponed NOT IN text_04\n",
      "se agregó:  0.0 en:  3 15\n",
      "postponed NOT IN text_05\n",
      "se agregó:  0.0 en:  4 15\n",
      "due NOT IN text_01\n",
      "se agregó:  0.0 en:  0 16\n",
      "due IN text_02\n",
      "se agregó:  1.0 en:  1 16\n",
      "due NOT IN text_03\n",
      "se agregó:  0.0 en:  2 16\n",
      "due NOT IN text_04\n",
      "se agregó:  0.0 en:  3 16\n",
      "due NOT IN text_05\n",
      "se agregó:  0.0 en:  4 16\n",
      "outbreak NOT IN text_01\n",
      "se agregó:  0.0 en:  0 17\n",
      "outbreak IN text_02\n",
      "se agregó:  1.0 en:  1 17\n",
      "outbreak NOT IN text_03\n",
      "se agregó:  0.0 en:  2 17\n",
      "outbreak NOT IN text_04\n",
      "se agregó:  0.0 en:  3 17\n",
      "outbreak NOT IN text_05\n",
      "se agregó:  0.0 en:  4 17\n",
      "f1 NOT IN text_01\n",
      "se agregó:  0.0 en:  0 18\n",
      "f1 IN text_02\n",
      "se agregó:  1.0 en:  1 18\n",
      "f1 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 18\n",
      "f1 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 18\n",
      "f1 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 18\n",
      "fia NOT IN text_01\n",
      "se agregó:  0.0 en:  0 19\n",
      "fia IN text_02\n",
      "se agregó:  1.0 en:  1 19\n",
      "fia NOT IN text_03\n",
      "se agregó:  0.0 en:  2 19\n",
      "fia NOT IN text_04\n",
      "se agregó:  0.0 en:  3 19\n",
      "fia NOT IN text_05\n",
      "se agregó:  0.0 en:  4 19\n",
      "accepted NOT IN text_01\n",
      "se agregó:  0.0 en:  0 20\n",
      "accepted IN text_02\n",
      "se agregó:  1.0 en:  1 20\n",
      "accepted NOT IN text_03\n",
      "se agregó:  0.0 en:  2 20\n",
      "accepted NOT IN text_04\n",
      "se agregó:  0.0 en:  3 20\n",
      "accepted NOT IN text_05\n",
      "se agregó:  0.0 en:  4 20\n",
      "request NOT IN text_01\n",
      "se agregó:  0.0 en:  0 21\n",
      "request IN text_02\n",
      "se agregó:  1.0 en:  1 21\n",
      "request NOT IN text_03\n",
      "se agregó:  0.0 en:  2 21\n",
      "request NOT IN text_04\n",
      "se agregó:  0.0 en:  3 21\n",
      "request NOT IN text_05\n",
      "se agregó:  0.0 en:  4 21\n",
      "promoter NOT IN text_01\n",
      "se agregó:  0.0 en:  0 22\n",
      "promoter IN text_02\n",
      "se agregó:  1.0 en:  1 22\n",
      "promoter NOT IN text_03\n",
      "se agregó:  0.0 en:  2 22\n",
      "promoter NOT IN text_04\n",
      "se agregó:  0.0 en:  3 22\n",
      "promoter NOT IN text_05\n",
      "se agregó:  0.0 en:  4 22\n",
      "postpone NOT IN text_01\n",
      "se agregó:  0.0 en:  0 23\n",
      "postpone IN text_02\n",
      "se agregó:  1.0 en:  1 23\n",
      "postpone NOT IN text_03\n",
      "se agregó:  0.0 en:  2 23\n",
      "postpone NOT IN text_04\n",
      "se agregó:  0.0 en:  3 23\n",
      "postpone NOT IN text_05\n",
      "se agregó:  0.0 en:  4 23\n",
      "event NOT IN text_01\n",
      "se agregó:  0.0 en:  0 24\n",
      "event IN text_02\n",
      "se agregó:  1.0 en:  1 24\n",
      "event NOT IN text_03\n",
      "se agregó:  0.0 en:  2 24\n",
      "event NOT IN text_04\n",
      "se agregó:  0.0 en:  3 24\n",
      "event NOT IN text_05\n",
      "se agregó:  0.0 en:  4 24\n",
      "continue NOT IN text_01\n",
      "se agregó:  0.0 en:  0 25\n",
      "continue IN text_02\n",
      "se agregó:  1.0 en:  1 25\n",
      "continue NOT IN text_03\n",
      "se agregó:  0.0 en:  2 25\n",
      "continue NOT IN text_04\n",
      "se agregó:  0.0 en:  3 25\n",
      "continue NOT IN text_05\n",
      "se agregó:  0.0 en:  4 25\n",
      "monitor NOT IN text_01\n",
      "se agregó:  0.0 en:  0 26\n",
      "monitor IN text_02\n",
      "se agregó:  1.0 en:  1 26\n",
      "monitor NOT IN text_03\n",
      "se agregó:  0.0 en:  2 26\n",
      "monitor NOT IN text_04\n",
      "se agregó:  0.0 en:  3 26\n",
      "monitor NOT IN text_05\n",
      "se agregó:  0.0 en:  4 26\n",
      "situation NOT IN text_01\n",
      "se agregó:  0.0 en:  0 27\n",
      "situation IN text_02\n",
      "se agregó:  1.0 en:  1 27\n",
      "situation NOT IN text_03\n",
      "se agregó:  0.0 en:  2 27\n",
      "situation NOT IN text_04\n",
      "se agregó:  0.0 en:  3 27\n",
      "situation NOT IN text_05\n",
      "se agregó:  0.0 en:  4 27\n",
      "assess NOT IN text_01\n",
      "se agregó:  0.0 en:  0 28\n",
      "assess IN text_02\n",
      "se agregó:  1.0 en:  1 28\n",
      "assess NOT IN text_03\n",
      "se agregó:  0.0 en:  2 28\n",
      "assess NOT IN text_04\n",
      "se agregó:  0.0 en:  3 28\n",
      "assess NOT IN text_05\n",
      "se agregó:  0.0 en:  4 28\n",
      "potential NOT IN text_01\n",
      "se agregó:  0.0 en:  0 29\n",
      "potential IN text_02\n",
      "se agregó:  1.0 en:  1 29\n",
      "potential NOT IN text_03\n",
      "se agregó:  0.0 en:  2 29\n",
      "potential NOT IN text_04\n",
      "se agregó:  0.0 en:  3 29\n",
      "potential NOT IN text_05\n",
      "se agregó:  0.0 en:  4 29\n",
      "alternative NOT IN text_01\n",
      "se agregó:  0.0 en:  0 30\n",
      "alternative IN text_02\n",
      "se agregó:  1.0 en:  1 30\n",
      "alternative NOT IN text_03\n",
      "se agregó:  0.0 en:  2 30\n",
      "alternative NOT IN text_04\n",
      "se agregó:  0.0 en:  3 30\n",
      "alternative NOT IN text_05\n",
      "se agregó:  0.0 en:  4 30\n",
      "dates NOT IN text_01\n",
      "se agregó:  0.0 en:  0 31\n",
      "dates IN text_02\n",
      "se agregó:  1.0 en:  1 31\n",
      "dates NOT IN text_03\n",
      "se agregó:  0.0 en:  2 31\n",
      "dates NOT IN text_04\n",
      "se agregó:  0.0 en:  3 31\n",
      "dates NOT IN text_05\n",
      "se agregó:  0.0 en:  4 31\n",
      "crea NOT IN text_01\n",
      "se agregó:  0.0 en:  0 32\n",
      "crea NOT IN text_02\n",
      "se agregó:  0.0 en:  1 32\n",
      "crea IN text_03\n",
      "se agregó:  1.0 en:  2 32\n",
      "crea IN text_04\n",
      "se agregó:  1.0 en:  3 32\n",
      "crea NOT IN text_05\n",
      "se agregó:  0.0 en:  4 32\n",
      "unam_mx NOT IN text_01\n",
      "se agregó:  0.0 en:  0 33\n",
      "unam_mx NOT IN text_02\n",
      "se agregó:  0.0 en:  1 33\n",
      "unam_mx IN text_03\n",
      "se agregó:  1.0 en:  2 33\n",
      "unam_mx IN text_04\n",
      "se agregó:  1.0 en:  3 33\n",
      "unam_mx NOT IN text_05\n",
      "se agregó:  0.0 en:  4 33\n",
      "licenciatura NOT IN text_01\n",
      "se agregó:  0.0 en:  0 34\n",
      "licenciatura NOT IN text_02\n",
      "se agregó:  0.0 en:  1 34\n",
      "licenciatura IN text_03\n",
      "se agregó:  1.0 en:  2 34\n",
      "licenciatura IN text_04\n",
      "se agregó:  1.0 en:  3 34\n",
      "licenciatura NOT IN text_05\n",
      "se agregó:  0.0 en:  4 34\n",
      "ingeniería NOT IN text_01\n",
      "se agregó:  0.0 en:  0 35\n",
      "ingeniería NOT IN text_02\n",
      "se agregó:  0.0 en:  1 35\n",
      "ingeniería IN text_03\n",
      "se agregó:  1.0 en:  2 35\n",
      "ingeniería IN text_04\n",
      "se agregó:  1.0 en:  3 35\n",
      "ingeniería NOT IN text_05\n",
      "se agregó:  0.0 en:  4 35\n",
      "aeroespacial NOT IN text_01\n",
      "se agregó:  0.0 en:  0 36\n",
      "aeroespacial NOT IN text_02\n",
      "se agregó:  0.0 en:  1 36\n",
      "aeroespacial IN text_03\n",
      "se agregó:  1.0 en:  2 36\n",
      "aeroespacial IN text_04\n",
      "se agregó:  1.0 en:  3 36\n",
      "aeroespacial NOT IN text_05\n",
      "se agregó:  0.0 en:  4 36\n",
      "impartirá NOT IN text_01\n",
      "se agregó:  0.0 en:  0 37\n",
      "impartirá NOT IN text_02\n",
      "se agregó:  0.0 en:  1 37\n",
      "impartirá IN text_03\n",
      "se agregó:  1.0 en:  2 37\n",
      "impartirá IN text_04\n",
      "se agregó:  1.0 en:  3 37\n",
      "impartirá NOT IN text_05\n",
      "se agregó:  0.0 en:  4 37\n",
      "facultad NOT IN text_01\n",
      "se agregó:  0.0 en:  0 38\n",
      "facultad NOT IN text_02\n",
      "se agregó:  0.0 en:  1 38\n",
      "facultad IN text_03\n",
      "se agregó:  1.0 en:  2 38\n",
      "facultad IN text_04\n",
      "se agregó:  1.0 en:  3 38\n",
      "facultad NOT IN text_05\n",
      "se agregó:  0.0 en:  4 38\n",
      "ciudad NOT IN text_01\n",
      "se agregó:  0.0 en:  0 39\n",
      "ciudad NOT IN text_02\n",
      "se agregó:  0.0 en:  1 39\n",
      "ciudad IN text_03\n",
      "se agregó:  1.0 en:  2 39\n",
      "ciudad IN text_04\n",
      "se agregó:  1.0 en:  3 39\n",
      "ciudad NOT IN text_05\n",
      "se agregó:  0.0 en:  4 39\n",
      "universitaria NOT IN text_01\n",
      "se agregó:  0.0 en:  0 40\n",
      "universitaria NOT IN text_02\n",
      "se agregó:  0.0 en:  1 40\n",
      "universitaria IN text_03\n",
      "se agregó:  1.0 en:  2 40\n",
      "universitaria IN text_04\n",
      "se agregó:  1.0 en:  3 40\n",
      "universitaria NOT IN text_05\n",
      "se agregó:  0.0 en:  4 40\n",
      "alumnos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 41\n",
      "alumnos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 41\n",
      "alumnos IN text_03\n",
      "se agregó:  1.0 en:  2 41\n",
      "alumnos IN text_04\n",
      "se agregó:  1.0 en:  3 41\n",
      "alumnos NOT IN text_05\n",
      "se agregó:  0.0 en:  4 41\n",
      "deberán NOT IN text_01\n",
      "se agregó:  0.0 en:  0 42\n",
      "deberán NOT IN text_02\n",
      "se agregó:  0.0 en:  1 42\n",
      "deberán IN text_03\n",
      "se agregó:  1.0 en:  2 42\n",
      "deberán IN text_04\n",
      "se agregó:  1.0 en:  3 42\n",
      "deberán NOT IN text_05\n",
      "se agregó:  0.0 en:  4 42\n",
      "cursar NOT IN text_01\n",
      "se agregó:  0.0 en:  0 43\n",
      "cursar NOT IN text_02\n",
      "se agregó:  0.0 en:  1 43\n",
      "cursar IN text_03\n",
      "se agregó:  1.0 en:  2 43\n",
      "cursar IN text_04\n",
      "se agregó:  1.0 en:  3 43\n",
      "cursar NOT IN text_05\n",
      "se agregó:  0.0 en:  4 43\n",
      "10 NOT IN text_01\n",
      "se agregó:  0.0 en:  0 44\n",
      "10 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 44\n",
      "10 IN text_03\n",
      "se agregó:  1.0 en:  2 44\n",
      "10 IN text_04\n",
      "se agregó:  1.0 en:  3 44\n",
      "10 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 44\n",
      "semestres NOT IN text_01\n",
      "se agregó:  0.0 en:  0 45\n",
      "semestres NOT IN text_02\n",
      "se agregó:  0.0 en:  1 45\n",
      "semestres IN text_03\n",
      "se agregó:  1.0 en:  2 45\n",
      "semestres IN text_04\n",
      "se agregó:  1.0 en:  3 45\n",
      "semestres NOT IN text_05\n",
      "se agregó:  0.0 en:  4 45\n",
      "cubrir NOT IN text_01\n",
      "se agregó:  0.0 en:  0 46\n",
      "cubrir NOT IN text_02\n",
      "se agregó:  0.0 en:  1 46\n",
      "cubrir IN text_03\n",
      "se agregó:  1.0 en:  2 46\n",
      "cubrir IN text_04\n",
      "se agregó:  1.0 en:  3 46\n",
      "cubrir NOT IN text_05\n",
      "se agregó:  0.0 en:  4 46\n",
      "450 NOT IN text_01\n",
      "se agregó:  0.0 en:  0 47\n",
      "450 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 47\n",
      "450 IN text_03\n",
      "se agregó:  1.0 en:  2 47\n",
      "450 IN text_04\n",
      "se agregó:  1.0 en:  3 47\n",
      "450 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 47\n",
      "créditos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 48\n",
      "créditos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 48\n",
      "créditos IN text_03\n",
      "se agregó:  1.0 en:  2 48\n",
      "créditos IN text_04\n",
      "se agregó:  1.0 en:  3 48\n",
      "créditos NOT IN text_05\n",
      "se agregó:  0.0 en:  4 48\n",
      "llegó NOT IN text_01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se agregó:  0.0 en:  0 49\n",
      "llegó NOT IN text_02\n",
      "se agregó:  0.0 en:  1 49\n",
      "llegó NOT IN text_03\n",
      "se agregó:  0.0 en:  2 49\n",
      "llegó NOT IN text_04\n",
      "se agregó:  0.0 en:  3 49\n",
      "llegó IN text_05\n",
      "se agregó:  1.0 en:  4 49\n",
      "encontramos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 50\n",
      "encontramos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 50\n",
      "encontramos NOT IN text_03\n",
      "se agregó:  0.0 en:  2 50\n",
      "encontramos NOT IN text_04\n",
      "se agregó:  0.0 en:  3 50\n",
      "encontramos IN text_05\n",
      "se agregó:  1.0 en:  4 50\n",
      "serie NOT IN text_01\n",
      "se agregó:  0.0 en:  0 51\n",
      "serie NOT IN text_02\n",
      "se agregó:  0.0 en:  1 51\n",
      "serie NOT IN text_03\n",
      "se agregó:  0.0 en:  2 51\n",
      "serie NOT IN text_04\n",
      "se agregó:  0.0 en:  3 51\n",
      "serie IN text_05\n",
      "se agregó:  1.0 en:  4 51\n",
      "estrenos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 52\n",
      "estrenos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 52\n",
      "estrenos NOT IN text_03\n",
      "se agregó:  0.0 en:  2 52\n",
      "estrenos NOT IN text_04\n",
      "se agregó:  0.0 en:  3 52\n",
      "estrenos IN text_05\n",
      "se agregó:  1.0 en:  4 52\n",
      "harán NOT IN text_01\n",
      "se agregó:  0.0 en:  0 53\n",
      "harán NOT IN text_02\n",
      "se agregó:  0.0 en:  1 53\n",
      "harán NOT IN text_03\n",
      "se agregó:  0.0 en:  2 53\n",
      "harán NOT IN text_04\n",
      "se agregó:  0.0 en:  3 53\n",
      "harán IN text_05\n",
      "se agregó:  1.0 en:  4 53\n",
      "iniciar NOT IN text_01\n",
      "se agregó:  0.0 en:  0 54\n",
      "iniciar NOT IN text_02\n",
      "se agregó:  0.0 en:  1 54\n",
      "iniciar NOT IN text_03\n",
      "se agregó:  0.0 en:  2 54\n",
      "iniciar NOT IN text_04\n",
      "se agregó:  0.0 en:  3 54\n",
      "iniciar IN text_05\n",
      "se agregó:  1.0 en:  4 54\n",
      "grande NOT IN text_01\n",
      "se agregó:  0.0 en:  0 55\n",
      "grande NOT IN text_02\n",
      "se agregó:  0.0 en:  1 55\n",
      "grande NOT IN text_03\n",
      "se agregó:  0.0 en:  2 55\n",
      "grande NOT IN text_04\n",
      "se agregó:  0.0 en:  3 55\n",
      "grande IN text_05\n",
      "se agregó:  1.0 en:  4 55\n",
      "lugar NOT IN text_01\n",
      "se agregó:  0.0 en:  0 56\n",
      "lugar NOT IN text_02\n",
      "se agregó:  0.0 en:  1 56\n",
      "lugar NOT IN text_03\n",
      "se agregó:  0.0 en:  2 56\n",
      "lugar NOT IN text_04\n",
      "se agregó:  0.0 en:  3 56\n",
      "lugar IN text_05\n",
      "se agregó:  1.0 en:  4 56\n",
      "dudas NOT IN text_01\n",
      "se agregó:  0.0 en:  0 57\n",
      "dudas NOT IN text_02\n",
      "se agregó:  0.0 en:  1 57\n",
      "dudas NOT IN text_03\n",
      "se agregó:  0.0 en:  2 57\n",
      "dudas NOT IN text_04\n",
      "se agregó:  0.0 en:  3 57\n",
      "dudas IN text_05\n",
      "se agregó:  1.0 en:  4 57\n",
      "regreso NOT IN text_01\n",
      "se agregó:  0.0 en:  0 58\n",
      "regreso NOT IN text_02\n",
      "se agregó:  0.0 en:  1 58\n",
      "regreso NOT IN text_03\n",
      "se agregó:  0.0 en:  2 58\n",
      "regreso NOT IN text_04\n",
      "se agregó:  0.0 en:  3 58\n",
      "regreso IN text_05\n",
      "se agregó:  1.0 en:  4 58\n",
      "cloud NOT IN text_01\n",
      "se agregó:  0.0 en:  0 59\n",
      "cloud NOT IN text_02\n",
      "se agregó:  0.0 en:  1 59\n",
      "cloud NOT IN text_03\n",
      "se agregó:  0.0 en:  2 59\n",
      "cloud NOT IN text_04\n",
      "se agregó:  0.0 en:  3 59\n",
      "cloud IN text_05\n",
      "se agregó:  1.0 en:  4 59\n",
      "tifa NOT IN text_01\n",
      "se agregó:  0.0 en:  0 60\n",
      "tifa NOT IN text_02\n",
      "se agregó:  0.0 en:  1 60\n",
      "tifa NOT IN text_03\n",
      "se agregó:  0.0 en:  2 60\n",
      "tifa NOT IN text_04\n",
      "se agregó:  0.0 en:  3 60\n",
      "tifa IN text_05\n",
      "se agregó:  1.0 en:  4 60\n",
      "aerith NOT IN text_01\n",
      "se agregó:  0.0 en:  0 61\n",
      "aerith NOT IN text_02\n",
      "se agregó:  0.0 en:  1 61\n",
      "aerith NOT IN text_03\n",
      "se agregó:  0.0 en:  2 61\n",
      "aerith NOT IN text_04\n",
      "se agregó:  0.0 en:  3 61\n",
      "aerith IN text_05\n",
      "se agregó:  1.0 en:  4 61\n",
      "final NOT IN text_01\n",
      "se agregó:  0.0 en:  0 62\n",
      "final NOT IN text_02\n",
      "se agregó:  0.0 en:  1 62\n",
      "final NOT IN text_03\n",
      "se agregó:  0.0 en:  2 62\n",
      "final NOT IN text_04\n",
      "se agregó:  0.0 en:  3 62\n",
      "final IN text_05\n",
      "se agregó:  1.0 en:  4 62\n",
      "fantasy NOT IN text_01\n",
      "se agregó:  0.0 en:  0 63\n",
      "fantasy NOT IN text_02\n",
      "se agregó:  0.0 en:  1 63\n",
      "fantasy NOT IN text_03\n",
      "se agregó:  0.0 en:  2 63\n",
      "fantasy NOT IN text_04\n",
      "se agregó:  0.0 en:  3 63\n",
      "fantasy IN text_05\n",
      "se agregó:  1.0 en:  4 63\n",
      "vii NOT IN text_01\n",
      "se agregó:  0.0 en:  0 64\n",
      "vii NOT IN text_02\n",
      "se agregó:  0.0 en:  1 64\n",
      "vii NOT IN text_03\n",
      "se agregó:  0.0 en:  2 64\n",
      "vii NOT IN text_04\n",
      "se agregó:  0.0 en:  3 64\n",
      "vii IN text_05\n",
      "se agregó:  1.0 en:  4 64\n",
      "remake NOT IN text_01\n",
      "se agregó:  0.0 en:  0 65\n",
      "remake NOT IN text_02\n",
      "se agregó:  0.0 en:  1 65\n",
      "remake NOT IN text_03\n",
      "se agregó:  0.0 en:  2 65\n",
      "remake NOT IN text_04\n",
      "se agregó:  0.0 en:  3 65\n",
      "remake IN text_05\n",
      "se agregó:  1.0 en:  4 65\n",
      "trata NOT IN text_01\n",
      "se agregó:  0.0 en:  0 66\n",
      "trata NOT IN text_02\n",
      "se agregó:  0.0 en:  1 66\n",
      "trata NOT IN text_03\n",
      "se agregó:  0.0 en:  2 66\n",
      "trata NOT IN text_04\n",
      "se agregó:  0.0 en:  3 66\n",
      "trata IN text_05\n",
      "se agregó:  1.0 en:  4 66\n",
      "solamente NOT IN text_01\n",
      "se agregó:  0.0 en:  0 67\n",
      "solamente NOT IN text_02\n",
      "se agregó:  0.0 en:  1 67\n",
      "solamente NOT IN text_03\n",
      "se agregó:  0.0 en:  2 67\n",
      "solamente NOT IN text_04\n",
      "se agregó:  0.0 en:  3 67\n",
      "solamente IN text_05\n",
      "se agregó:  1.0 en:  4 67\n",
      "juegos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 68\n",
      "juegos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 68\n",
      "juegos NOT IN text_03\n",
      "se agregó:  0.0 en:  2 68\n",
      "juegos NOT IN text_04\n",
      "se agregó:  0.0 en:  3 68\n",
      "juegos IN text_05\n",
      "se agregó:  1.0 en:  4 68\n",
      "esperados NOT IN text_01\n",
      "se agregó:  0.0 en:  0 69\n",
      "esperados NOT IN text_02\n",
      "se agregó:  0.0 en:  1 69\n",
      "esperados NOT IN text_03\n",
      "se agregó:  0.0 en:  2 69\n",
      "esperados NOT IN text_04\n",
      "se agregó:  0.0 en:  3 69\n",
      "esperados IN text_05\n",
      "se agregó:  1.0 en:  4 69\n",
      "año NOT IN text_01\n",
      "se agregó:  0.0 en:  0 70\n",
      "año NOT IN text_02\n",
      "se agregó:  0.0 en:  1 70\n",
      "año NOT IN text_03\n",
      "se agregó:  0.0 en:  2 70\n",
      "año NOT IN text_04\n",
      "se agregó:  0.0 en:  3 70\n",
      "año IN text_05\n",
      "se agregó:  1.0 en:  4 70\n",
      "sino NOT IN text_01\n",
      "se agregó:  0.0 en:  0 71\n",
      "sino NOT IN text_02\n",
      "se agregó:  0.0 en:  1 71\n",
      "sino NOT IN text_03\n",
      "se agregó:  0.0 en:  2 71\n",
      "sino NOT IN text_04\n",
      "se agregó:  0.0 en:  3 71\n",
      "sino IN text_05\n",
      "se agregó:  1.0 en:  4 71\n",
      "bien NOT IN text_01\n",
      "se agregó:  0.0 en:  0 72\n",
      "bien NOT IN text_02\n",
      "se agregó:  0.0 en:  1 72\n",
      "bien NOT IN text_03\n",
      "se agregó:  0.0 en:  2 72\n",
      "bien NOT IN text_04\n",
      "se agregó:  0.0 en:  3 72\n",
      "bien IN text_05\n",
      "se agregó:  1.0 en:  4 72\n",
      "década NOT IN text_01\n",
      "se agregó:  0.0 en:  0 73\n",
      "década NOT IN text_02\n",
      "se agregó:  0.0 en:  1 73\n",
      "década NOT IN text_03\n",
      "se agregó:  0.0 en:  2 73\n",
      "década NOT IN text_04\n",
      "se agregó:  0.0 en:  3 73\n",
      "década IN text_05\n",
      "se agregó:  1.0 en:  4 73\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for word_termns in dicc_termns: #dicc_termns todos los términos\n",
    "#    print()\n",
    "    for word_texts in dicc_texts: #dicc_texts todos los textos\n",
    "#        print(\"EVALUAR:\", word_termns, \"EN: \", word_texts)\n",
    "        if(word_termns in dicc_texts[word_texts]): #si está\n",
    "            print(word_termns, \"IN\", word_texts)\n",
    "            \n",
    "            matrix[j, i] = 1\n",
    "            \n",
    "        elif(word_termns not in dicc_texts[word_texts]): # si no está\n",
    "            print(word_termns, \"NOT IN\", word_texts)\n",
    "            \n",
    "            matrix[j, i] = 0\n",
    "            \n",
    "            \n",
    "        print(\"se agregó: \", matrix[j,i], \"en: \", j, i)\n",
    "            \n",
    "        j = j + 1\n",
    "        \n",
    "    j = 0\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 74)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-a1bc42962407>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "matrix[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062017367294604234"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t01_t02 = dot(matrix[0],matrix[1])/(norm(matrix[0])*norm(matrix[1]))\n",
    "bin_cos_t01_t02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t01_t03 = dot(matrix[0],matrix[2])/(norm(matrix[0])*norm(matrix[2]))\n",
    "bin_cos_t01_t03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t01_t04 = dot(matrix[0],matrix[3])/(norm(matrix[0])*norm(matrix[3]))\n",
    "bin_cos_t01_t04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t01_t05 = dot(matrix[0],matrix[4])/(norm(matrix[0])*norm(matrix[4]))\n",
    "bin_cos_t01_t05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t02_t03 = dot(matrix[1],matrix[2])/(norm(matrix[1])*norm(matrix[2]))\n",
    "bin_cos_t02_t03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t02_t04 = dot(matrix[1],matrix[3])/(norm(matrix[1])*norm(matrix[3]))\n",
    "bin_cos_t02_t04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043852900965351466"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t02_t05 = dot(matrix[1],matrix[4])/(norm(matrix[1])*norm(matrix[4]))\n",
    "bin_cos_t02_t05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t03_t04 = dot(matrix[2],matrix[3])/(norm(matrix[2])*norm(matrix[3]))\n",
    "bin_cos_t03_t04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t03_t05 = dot(matrix[2],matrix[4])/(norm(matrix[2])*norm(matrix[4]))\n",
    "bin_cos_t03_t05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_cos_t04_t05 = dot(matrix[3],matrix[4])/(norm(matrix[3])*norm(matrix[4]))\n",
    "bin_cos_t04_t05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz termino documento con frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((len(dicc_texts), len(dicc_termns))) # Pre-allocate matrix\n",
    "#matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispara IN text_01\n",
      "se agregó:  1.0 en:  0 0\n",
      "dispara NOT IN text_02\n",
      "se agregó:  0.0 en:  1 0\n",
      "dispara NOT IN text_03\n",
      "se agregó:  0.0 en:  2 0\n",
      "dispara NOT IN text_04\n",
      "se agregó:  0.0 en:  3 0\n",
      "dispara NOT IN text_05\n",
      "se agregó:  0.0 en:  4 0\n",
      "coronavirus IN text_01\n",
      "se agregó:  3.0 en:  0 1\n",
      "coronavirus IN text_02\n",
      "se agregó:  3.0 en:  1 1\n",
      "coronavirus NOT IN text_03\n",
      "se agregó:  0.0 en:  2 1\n",
      "coronavirus NOT IN text_04\n",
      "se agregó:  0.0 en:  3 1\n",
      "coronavirus NOT IN text_05\n",
      "se agregó:  0.0 en:  4 1\n",
      "cifra IN text_01\n",
      "se agregó:  2.0 en:  0 2\n",
      "cifra NOT IN text_02\n",
      "se agregó:  0.0 en:  1 2\n",
      "cifra NOT IN text_03\n",
      "se agregó:  0.0 en:  2 2\n",
      "cifra NOT IN text_04\n",
      "se agregó:  0.0 en:  3 2\n",
      "cifra NOT IN text_05\n",
      "se agregó:  0.0 en:  4 2\n",
      "muertos IN text_01\n",
      "se agregó:  1.0 en:  0 3\n",
      "muertos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 3\n",
      "muertos NOT IN text_03\n",
      "se agregó:  0.0 en:  2 3\n",
      "muertos NOT IN text_04\n",
      "se agregó:  0.0 en:  3 3\n",
      "muertos NOT IN text_05\n",
      "se agregó:  0.0 en:  4 3\n",
      "aumenta IN text_01\n",
      "se agregó:  2.0 en:  0 4\n",
      "aumenta NOT IN text_02\n",
      "se agregó:  0.0 en:  1 4\n",
      "aumenta NOT IN text_03\n",
      "se agregó:  0.0 en:  2 4\n",
      "aumenta NOT IN text_04\n",
      "se agregó:  0.0 en:  3 4\n",
      "aumenta NOT IN text_05\n",
      "se agregó:  0.0 en:  4 4\n",
      "242 IN text_01\n",
      "se agregó:  1.0 en:  0 5\n",
      "242 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 5\n",
      "242 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 5\n",
      "242 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 5\n",
      "242 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 5\n",
      "provincia IN text_01\n",
      "se agregó:  1.0 en:  0 6\n",
      "provincia NOT IN text_02\n",
      "se agregó:  0.0 en:  1 6\n",
      "provincia NOT IN text_03\n",
      "se agregó:  0.0 en:  2 6\n",
      "provincia NOT IN text_04\n",
      "se agregó:  0.0 en:  3 6\n",
      "provincia NOT IN text_05\n",
      "se agregó:  0.0 en:  4 6\n",
      "hubei IN text_01\n",
      "se agregó:  1.0 en:  0 7\n",
      "hubei NOT IN text_02\n",
      "se agregó:  0.0 en:  1 7\n",
      "hubei NOT IN text_03\n",
      "se agregó:  0.0 en:  2 7\n",
      "hubei NOT IN text_04\n",
      "se agregó:  0.0 en:  3 7\n",
      "hubei NOT IN text_05\n",
      "se agregó:  0.0 en:  4 7\n",
      "mientras IN text_01\n",
      "se agregó:  1.0 en:  0 8\n",
      "mientras NOT IN text_02\n",
      "se agregó:  0.0 en:  1 8\n",
      "mientras NOT IN text_03\n",
      "se agregó:  0.0 en:  2 8\n",
      "mientras NOT IN text_04\n",
      "se agregó:  0.0 en:  3 8\n",
      "mientras NOT IN text_05\n",
      "se agregó:  0.0 en:  4 8\n",
      "mundial IN text_01\n",
      "se agregó:  1.0 en:  0 9\n",
      "mundial NOT IN text_02\n",
      "se agregó:  0.0 en:  1 9\n",
      "mundial NOT IN text_03\n",
      "se agregó:  0.0 en:  2 9\n",
      "mundial NOT IN text_04\n",
      "se agregó:  0.0 en:  3 9\n",
      "mundial NOT IN text_05\n",
      "se agregó:  0.0 en:  4 9\n",
      "muertes IN text_01\n",
      "se agregó:  1.0 en:  0 10\n",
      "muertes NOT IN text_02\n",
      "se agregó:  0.0 en:  1 10\n",
      "muertes NOT IN text_03\n",
      "se agregó:  0.0 en:  2 10\n",
      "muertes NOT IN text_04\n",
      "se agregó:  0.0 en:  3 10\n",
      "muertes NOT IN text_05\n",
      "se agregó:  0.0 en:  4 10\n",
      "1 IN text_01\n",
      "se agregó:  1.0 en:  0 11\n",
      "1 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 11\n",
      "1 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 11\n",
      "1 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 11\n",
      "1 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 11\n",
      "357 IN text_01\n",
      "se agregó:  1.0 en:  0 12\n",
      "357 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 12\n",
      "357 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 12\n",
      "357 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 12\n",
      "357 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 12\n",
      "2020 NOT IN text_01\n",
      "se agregó:  0.0 en:  0 13\n",
      "2020 IN text_02\n",
      "se agregó:  2.0 en:  1 13\n",
      "2020 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 13\n",
      "2020 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 13\n",
      "2020 IN text_05\n",
      "se agregó:  2.0 en:  4 13\n",
      "chinesegp NOT IN text_01\n",
      "se agregó:  0.0 en:  0 14\n",
      "chinesegp IN text_02\n",
      "se agregó:  1.0 en:  1 14\n",
      "chinesegp NOT IN text_03\n",
      "se agregó:  0.0 en:  2 14\n",
      "chinesegp NOT IN text_04\n",
      "se agregó:  0.0 en:  3 14\n",
      "chinesegp NOT IN text_05\n",
      "se agregó:  0.0 en:  4 14\n",
      "postponed NOT IN text_01\n",
      "se agregó:  0.0 en:  0 15\n",
      "postponed IN text_02\n",
      "se agregó:  1.0 en:  1 15\n",
      "postponed NOT IN text_03\n",
      "se agregó:  0.0 en:  2 15\n",
      "postponed NOT IN text_04\n",
      "se agregó:  0.0 en:  3 15\n",
      "postponed NOT IN text_05\n",
      "se agregó:  0.0 en:  4 15\n",
      "due NOT IN text_01\n",
      "se agregó:  0.0 en:  0 16\n",
      "due IN text_02\n",
      "se agregó:  1.0 en:  1 16\n",
      "due NOT IN text_03\n",
      "se agregó:  0.0 en:  2 16\n",
      "due NOT IN text_04\n",
      "se agregó:  0.0 en:  3 16\n",
      "due NOT IN text_05\n",
      "se agregó:  0.0 en:  4 16\n",
      "outbreak NOT IN text_01\n",
      "se agregó:  0.0 en:  0 17\n",
      "outbreak IN text_02\n",
      "se agregó:  1.0 en:  1 17\n",
      "outbreak NOT IN text_03\n",
      "se agregó:  0.0 en:  2 17\n",
      "outbreak NOT IN text_04\n",
      "se agregó:  0.0 en:  3 17\n",
      "outbreak NOT IN text_05\n",
      "se agregó:  0.0 en:  4 17\n",
      "f1 NOT IN text_01\n",
      "se agregó:  0.0 en:  0 18\n",
      "f1 IN text_02\n",
      "se agregó:  1.0 en:  1 18\n",
      "f1 NOT IN text_03\n",
      "se agregó:  0.0 en:  2 18\n",
      "f1 NOT IN text_04\n",
      "se agregó:  0.0 en:  3 18\n",
      "f1 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 18\n",
      "fia NOT IN text_01\n",
      "se agregó:  0.0 en:  0 19\n",
      "fia IN text_02\n",
      "se agregó:  1.0 en:  1 19\n",
      "fia NOT IN text_03\n",
      "se agregó:  0.0 en:  2 19\n",
      "fia NOT IN text_04\n",
      "se agregó:  0.0 en:  3 19\n",
      "fia NOT IN text_05\n",
      "se agregó:  0.0 en:  4 19\n",
      "accepted NOT IN text_01\n",
      "se agregó:  0.0 en:  0 20\n",
      "accepted IN text_02\n",
      "se agregó:  1.0 en:  1 20\n",
      "accepted NOT IN text_03\n",
      "se agregó:  0.0 en:  2 20\n",
      "accepted NOT IN text_04\n",
      "se agregó:  0.0 en:  3 20\n",
      "accepted NOT IN text_05\n",
      "se agregó:  0.0 en:  4 20\n",
      "request NOT IN text_01\n",
      "se agregó:  0.0 en:  0 21\n",
      "request IN text_02\n",
      "se agregó:  1.0 en:  1 21\n",
      "request NOT IN text_03\n",
      "se agregó:  0.0 en:  2 21\n",
      "request NOT IN text_04\n",
      "se agregó:  0.0 en:  3 21\n",
      "request NOT IN text_05\n",
      "se agregó:  0.0 en:  4 21\n",
      "promoter NOT IN text_01\n",
      "se agregó:  0.0 en:  0 22\n",
      "promoter IN text_02\n",
      "se agregó:  1.0 en:  1 22\n",
      "promoter NOT IN text_03\n",
      "se agregó:  0.0 en:  2 22\n",
      "promoter NOT IN text_04\n",
      "se agregó:  0.0 en:  3 22\n",
      "promoter NOT IN text_05\n",
      "se agregó:  0.0 en:  4 22\n",
      "postpone NOT IN text_01\n",
      "se agregó:  0.0 en:  0 23\n",
      "postpone IN text_02\n",
      "se agregó:  1.0 en:  1 23\n",
      "postpone NOT IN text_03\n",
      "se agregó:  0.0 en:  2 23\n",
      "postpone NOT IN text_04\n",
      "se agregó:  0.0 en:  3 23\n",
      "postpone NOT IN text_05\n",
      "se agregó:  0.0 en:  4 23\n",
      "event NOT IN text_01\n",
      "se agregó:  0.0 en:  0 24\n",
      "event IN text_02\n",
      "se agregó:  1.0 en:  1 24\n",
      "event NOT IN text_03\n",
      "se agregó:  0.0 en:  2 24\n",
      "event NOT IN text_04\n",
      "se agregó:  0.0 en:  3 24\n",
      "event NOT IN text_05\n",
      "se agregó:  0.0 en:  4 24\n",
      "continue NOT IN text_01\n",
      "se agregó:  0.0 en:  0 25\n",
      "continue IN text_02\n",
      "se agregó:  1.0 en:  1 25\n",
      "continue NOT IN text_03\n",
      "se agregó:  0.0 en:  2 25\n",
      "continue NOT IN text_04\n",
      "se agregó:  0.0 en:  3 25\n",
      "continue NOT IN text_05\n",
      "se agregó:  0.0 en:  4 25\n",
      "monitor NOT IN text_01\n",
      "se agregó:  0.0 en:  0 26\n",
      "monitor IN text_02\n",
      "se agregó:  1.0 en:  1 26\n",
      "monitor NOT IN text_03\n",
      "se agregó:  0.0 en:  2 26\n",
      "monitor NOT IN text_04\n",
      "se agregó:  0.0 en:  3 26\n",
      "monitor NOT IN text_05\n",
      "se agregó:  0.0 en:  4 26\n",
      "situation NOT IN text_01\n",
      "se agregó:  0.0 en:  0 27\n",
      "situation IN text_02\n",
      "se agregó:  1.0 en:  1 27\n",
      "situation NOT IN text_03\n",
      "se agregó:  0.0 en:  2 27\n",
      "situation NOT IN text_04\n",
      "se agregó:  0.0 en:  3 27\n",
      "situation NOT IN text_05\n",
      "se agregó:  0.0 en:  4 27\n",
      "assess NOT IN text_01\n",
      "se agregó:  0.0 en:  0 28\n",
      "assess IN text_02\n",
      "se agregó:  1.0 en:  1 28\n",
      "assess NOT IN text_03\n",
      "se agregó:  0.0 en:  2 28\n",
      "assess NOT IN text_04\n",
      "se agregó:  0.0 en:  3 28\n",
      "assess NOT IN text_05\n",
      "se agregó:  0.0 en:  4 28\n",
      "potential NOT IN text_01\n",
      "se agregó:  0.0 en:  0 29\n",
      "potential IN text_02\n",
      "se agregó:  1.0 en:  1 29\n",
      "potential NOT IN text_03\n",
      "se agregó:  0.0 en:  2 29\n",
      "potential NOT IN text_04\n",
      "se agregó:  0.0 en:  3 29\n",
      "potential NOT IN text_05\n",
      "se agregó:  0.0 en:  4 29\n",
      "alternative NOT IN text_01\n",
      "se agregó:  0.0 en:  0 30\n",
      "alternative IN text_02\n",
      "se agregó:  1.0 en:  1 30\n",
      "alternative NOT IN text_03\n",
      "se agregó:  0.0 en:  2 30\n",
      "alternative NOT IN text_04\n",
      "se agregó:  0.0 en:  3 30\n",
      "alternative NOT IN text_05\n",
      "se agregó:  0.0 en:  4 30\n",
      "dates NOT IN text_01\n",
      "se agregó:  0.0 en:  0 31\n",
      "dates IN text_02\n",
      "se agregó:  1.0 en:  1 31\n",
      "dates NOT IN text_03\n",
      "se agregó:  0.0 en:  2 31\n",
      "dates NOT IN text_04\n",
      "se agregó:  0.0 en:  3 31\n",
      "dates NOT IN text_05\n",
      "se agregó:  0.0 en:  4 31\n",
      "crea NOT IN text_01\n",
      "se agregó:  0.0 en:  0 32\n",
      "crea NOT IN text_02\n",
      "se agregó:  0.0 en:  1 32\n",
      "crea IN text_03\n",
      "se agregó:  2.0 en:  2 32\n",
      "crea IN text_04\n",
      "se agregó:  2.0 en:  3 32\n",
      "crea NOT IN text_05\n",
      "se agregó:  0.0 en:  4 32\n",
      "unam_mx NOT IN text_01\n",
      "se agregó:  0.0 en:  0 33\n",
      "unam_mx NOT IN text_02\n",
      "se agregó:  0.0 en:  1 33\n",
      "unam_mx IN text_03\n",
      "se agregó:  2.0 en:  2 33\n",
      "unam_mx IN text_04\n",
      "se agregó:  2.0 en:  3 33\n",
      "unam_mx NOT IN text_05\n",
      "se agregó:  0.0 en:  4 33\n",
      "licenciatura NOT IN text_01\n",
      "se agregó:  0.0 en:  0 34\n",
      "licenciatura NOT IN text_02\n",
      "se agregó:  0.0 en:  1 34\n",
      "licenciatura IN text_03\n",
      "se agregó:  2.0 en:  2 34\n",
      "licenciatura IN text_04\n",
      "se agregó:  2.0 en:  3 34\n",
      "licenciatura NOT IN text_05\n",
      "se agregó:  0.0 en:  4 34\n",
      "ingeniería NOT IN text_01\n",
      "se agregó:  0.0 en:  0 35\n",
      "ingeniería NOT IN text_02\n",
      "se agregó:  0.0 en:  1 35\n",
      "ingeniería IN text_03\n",
      "se agregó:  4.0 en:  2 35\n",
      "ingeniería IN text_04\n",
      "se agregó:  4.0 en:  3 35\n",
      "ingeniería NOT IN text_05\n",
      "se agregó:  0.0 en:  4 35\n",
      "aeroespacial NOT IN text_01\n",
      "se agregó:  0.0 en:  0 36\n",
      "aeroespacial NOT IN text_02\n",
      "se agregó:  0.0 en:  1 36\n",
      "aeroespacial IN text_03\n",
      "se agregó:  2.0 en:  2 36\n",
      "aeroespacial IN text_04\n",
      "se agregó:  2.0 en:  3 36\n",
      "aeroespacial NOT IN text_05\n",
      "se agregó:  0.0 en:  4 36\n",
      "impartirá NOT IN text_01\n",
      "se agregó:  0.0 en:  0 37\n",
      "impartirá NOT IN text_02\n",
      "se agregó:  0.0 en:  1 37\n",
      "impartirá IN text_03\n",
      "se agregó:  2.0 en:  2 37\n",
      "impartirá IN text_04\n",
      "se agregó:  2.0 en:  3 37\n",
      "impartirá NOT IN text_05\n",
      "se agregó:  0.0 en:  4 37\n",
      "facultad NOT IN text_01\n",
      "se agregó:  0.0 en:  0 38\n",
      "facultad NOT IN text_02\n",
      "se agregó:  0.0 en:  1 38\n",
      "facultad IN text_03\n",
      "se agregó:  2.0 en:  2 38\n",
      "facultad IN text_04\n",
      "se agregó:  2.0 en:  3 38\n",
      "facultad NOT IN text_05\n",
      "se agregó:  0.0 en:  4 38\n",
      "ciudad NOT IN text_01\n",
      "se agregó:  0.0 en:  0 39\n",
      "ciudad NOT IN text_02\n",
      "se agregó:  0.0 en:  1 39\n",
      "ciudad IN text_03\n",
      "se agregó:  2.0 en:  2 39\n",
      "ciudad IN text_04\n",
      "se agregó:  2.0 en:  3 39\n",
      "ciudad NOT IN text_05\n",
      "se agregó:  0.0 en:  4 39\n",
      "universitaria NOT IN text_01\n",
      "se agregó:  0.0 en:  0 40\n",
      "universitaria NOT IN text_02\n",
      "se agregó:  0.0 en:  1 40\n",
      "universitaria IN text_03\n",
      "se agregó:  2.0 en:  2 40\n",
      "universitaria IN text_04\n",
      "se agregó:  2.0 en:  3 40\n",
      "universitaria NOT IN text_05\n",
      "se agregó:  0.0 en:  4 40\n",
      "alumnos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 41\n",
      "alumnos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 41\n",
      "alumnos IN text_03\n",
      "se agregó:  2.0 en:  2 41\n",
      "alumnos IN text_04\n",
      "se agregó:  2.0 en:  3 41\n",
      "alumnos NOT IN text_05\n",
      "se agregó:  0.0 en:  4 41\n",
      "deberán NOT IN text_01\n",
      "se agregó:  0.0 en:  0 42\n",
      "deberán NOT IN text_02\n",
      "se agregó:  0.0 en:  1 42\n",
      "deberán IN text_03\n",
      "se agregó:  2.0 en:  2 42\n",
      "deberán IN text_04\n",
      "se agregó:  2.0 en:  3 42\n",
      "deberán NOT IN text_05\n",
      "se agregó:  0.0 en:  4 42\n",
      "cursar NOT IN text_01\n",
      "se agregó:  0.0 en:  0 43\n",
      "cursar NOT IN text_02\n",
      "se agregó:  0.0 en:  1 43\n",
      "cursar IN text_03\n",
      "se agregó:  2.0 en:  2 43\n",
      "cursar IN text_04\n",
      "se agregó:  2.0 en:  3 43\n",
      "cursar NOT IN text_05\n",
      "se agregó:  0.0 en:  4 43\n",
      "10 NOT IN text_01\n",
      "se agregó:  0.0 en:  0 44\n",
      "10 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 44\n",
      "10 IN text_03\n",
      "se agregó:  2.0 en:  2 44\n",
      "10 IN text_04\n",
      "se agregó:  2.0 en:  3 44\n",
      "10 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 44\n",
      "semestres NOT IN text_01\n",
      "se agregó:  0.0 en:  0 45\n",
      "semestres NOT IN text_02\n",
      "se agregó:  0.0 en:  1 45\n",
      "semestres IN text_03\n",
      "se agregó:  2.0 en:  2 45\n",
      "semestres IN text_04\n",
      "se agregó:  2.0 en:  3 45\n",
      "semestres NOT IN text_05\n",
      "se agregó:  0.0 en:  4 45\n",
      "cubrir NOT IN text_01\n",
      "se agregó:  0.0 en:  0 46\n",
      "cubrir NOT IN text_02\n",
      "se agregó:  0.0 en:  1 46\n",
      "cubrir IN text_03\n",
      "se agregó:  2.0 en:  2 46\n",
      "cubrir IN text_04\n",
      "se agregó:  2.0 en:  3 46\n",
      "cubrir NOT IN text_05\n",
      "se agregó:  0.0 en:  4 46\n",
      "450 NOT IN text_01\n",
      "se agregó:  0.0 en:  0 47\n",
      "450 NOT IN text_02\n",
      "se agregó:  0.0 en:  1 47\n",
      "450 IN text_03\n",
      "se agregó:  2.0 en:  2 47\n",
      "450 IN text_04\n",
      "se agregó:  2.0 en:  3 47\n",
      "450 NOT IN text_05\n",
      "se agregó:  0.0 en:  4 47\n",
      "créditos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 48\n",
      "créditos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 48\n",
      "créditos IN text_03\n",
      "se agregó:  2.0 en:  2 48\n",
      "créditos IN text_04\n",
      "se agregó:  2.0 en:  3 48\n",
      "créditos NOT IN text_05\n",
      "se agregó:  0.0 en:  4 48\n",
      "llegó NOT IN text_01\n",
      "se agregó:  0.0 en:  0 49\n",
      "llegó NOT IN text_02\n",
      "se agregó:  0.0 en:  1 49\n",
      "llegó NOT IN text_03\n",
      "se agregó:  0.0 en:  2 49\n",
      "llegó NOT IN text_04\n",
      "se agregó:  0.0 en:  3 49\n",
      "llegó IN text_05\n",
      "se agregó:  1.0 en:  4 49\n",
      "encontramos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 50\n",
      "encontramos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encontramos NOT IN text_03\n",
      "se agregó:  0.0 en:  2 50\n",
      "encontramos NOT IN text_04\n",
      "se agregó:  0.0 en:  3 50\n",
      "encontramos IN text_05\n",
      "se agregó:  1.0 en:  4 50\n",
      "serie NOT IN text_01\n",
      "se agregó:  0.0 en:  0 51\n",
      "serie NOT IN text_02\n",
      "se agregó:  0.0 en:  1 51\n",
      "serie NOT IN text_03\n",
      "se agregó:  0.0 en:  2 51\n",
      "serie NOT IN text_04\n",
      "se agregó:  0.0 en:  3 51\n",
      "serie IN text_05\n",
      "se agregó:  1.0 en:  4 51\n",
      "estrenos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 52\n",
      "estrenos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 52\n",
      "estrenos NOT IN text_03\n",
      "se agregó:  0.0 en:  2 52\n",
      "estrenos NOT IN text_04\n",
      "se agregó:  0.0 en:  3 52\n",
      "estrenos IN text_05\n",
      "se agregó:  1.0 en:  4 52\n",
      "harán NOT IN text_01\n",
      "se agregó:  0.0 en:  0 53\n",
      "harán NOT IN text_02\n",
      "se agregó:  0.0 en:  1 53\n",
      "harán NOT IN text_03\n",
      "se agregó:  0.0 en:  2 53\n",
      "harán NOT IN text_04\n",
      "se agregó:  0.0 en:  3 53\n",
      "harán IN text_05\n",
      "se agregó:  1.0 en:  4 53\n",
      "iniciar NOT IN text_01\n",
      "se agregó:  0.0 en:  0 54\n",
      "iniciar NOT IN text_02\n",
      "se agregó:  0.0 en:  1 54\n",
      "iniciar NOT IN text_03\n",
      "se agregó:  0.0 en:  2 54\n",
      "iniciar NOT IN text_04\n",
      "se agregó:  0.0 en:  3 54\n",
      "iniciar IN text_05\n",
      "se agregó:  1.0 en:  4 54\n",
      "grande NOT IN text_01\n",
      "se agregó:  0.0 en:  0 55\n",
      "grande NOT IN text_02\n",
      "se agregó:  0.0 en:  1 55\n",
      "grande NOT IN text_03\n",
      "se agregó:  0.0 en:  2 55\n",
      "grande NOT IN text_04\n",
      "se agregó:  0.0 en:  3 55\n",
      "grande IN text_05\n",
      "se agregó:  1.0 en:  4 55\n",
      "lugar NOT IN text_01\n",
      "se agregó:  0.0 en:  0 56\n",
      "lugar NOT IN text_02\n",
      "se agregó:  0.0 en:  1 56\n",
      "lugar NOT IN text_03\n",
      "se agregó:  0.0 en:  2 56\n",
      "lugar NOT IN text_04\n",
      "se agregó:  0.0 en:  3 56\n",
      "lugar IN text_05\n",
      "se agregó:  1.0 en:  4 56\n",
      "dudas NOT IN text_01\n",
      "se agregó:  0.0 en:  0 57\n",
      "dudas NOT IN text_02\n",
      "se agregó:  0.0 en:  1 57\n",
      "dudas NOT IN text_03\n",
      "se agregó:  0.0 en:  2 57\n",
      "dudas NOT IN text_04\n",
      "se agregó:  0.0 en:  3 57\n",
      "dudas IN text_05\n",
      "se agregó:  1.0 en:  4 57\n",
      "regreso NOT IN text_01\n",
      "se agregó:  0.0 en:  0 58\n",
      "regreso NOT IN text_02\n",
      "se agregó:  0.0 en:  1 58\n",
      "regreso NOT IN text_03\n",
      "se agregó:  0.0 en:  2 58\n",
      "regreso NOT IN text_04\n",
      "se agregó:  0.0 en:  3 58\n",
      "regreso IN text_05\n",
      "se agregó:  1.0 en:  4 58\n",
      "cloud NOT IN text_01\n",
      "se agregó:  0.0 en:  0 59\n",
      "cloud NOT IN text_02\n",
      "se agregó:  0.0 en:  1 59\n",
      "cloud NOT IN text_03\n",
      "se agregó:  0.0 en:  2 59\n",
      "cloud NOT IN text_04\n",
      "se agregó:  0.0 en:  3 59\n",
      "cloud IN text_05\n",
      "se agregó:  1.0 en:  4 59\n",
      "tifa NOT IN text_01\n",
      "se agregó:  0.0 en:  0 60\n",
      "tifa NOT IN text_02\n",
      "se agregó:  0.0 en:  1 60\n",
      "tifa NOT IN text_03\n",
      "se agregó:  0.0 en:  2 60\n",
      "tifa NOT IN text_04\n",
      "se agregó:  0.0 en:  3 60\n",
      "tifa IN text_05\n",
      "se agregó:  1.0 en:  4 60\n",
      "aerith NOT IN text_01\n",
      "se agregó:  0.0 en:  0 61\n",
      "aerith NOT IN text_02\n",
      "se agregó:  0.0 en:  1 61\n",
      "aerith NOT IN text_03\n",
      "se agregó:  0.0 en:  2 61\n",
      "aerith NOT IN text_04\n",
      "se agregó:  0.0 en:  3 61\n",
      "aerith IN text_05\n",
      "se agregó:  1.0 en:  4 61\n",
      "final NOT IN text_01\n",
      "se agregó:  0.0 en:  0 62\n",
      "final NOT IN text_02\n",
      "se agregó:  0.0 en:  1 62\n",
      "final NOT IN text_03\n",
      "se agregó:  0.0 en:  2 62\n",
      "final NOT IN text_04\n",
      "se agregó:  0.0 en:  3 62\n",
      "final IN text_05\n",
      "se agregó:  1.0 en:  4 62\n",
      "fantasy NOT IN text_01\n",
      "se agregó:  0.0 en:  0 63\n",
      "fantasy NOT IN text_02\n",
      "se agregó:  0.0 en:  1 63\n",
      "fantasy NOT IN text_03\n",
      "se agregó:  0.0 en:  2 63\n",
      "fantasy NOT IN text_04\n",
      "se agregó:  0.0 en:  3 63\n",
      "fantasy IN text_05\n",
      "se agregó:  1.0 en:  4 63\n",
      "vii NOT IN text_01\n",
      "se agregó:  0.0 en:  0 64\n",
      "vii NOT IN text_02\n",
      "se agregó:  0.0 en:  1 64\n",
      "vii NOT IN text_03\n",
      "se agregó:  0.0 en:  2 64\n",
      "vii NOT IN text_04\n",
      "se agregó:  0.0 en:  3 64\n",
      "vii IN text_05\n",
      "se agregó:  1.0 en:  4 64\n",
      "remake NOT IN text_01\n",
      "se agregó:  0.0 en:  0 65\n",
      "remake NOT IN text_02\n",
      "se agregó:  0.0 en:  1 65\n",
      "remake NOT IN text_03\n",
      "se agregó:  0.0 en:  2 65\n",
      "remake NOT IN text_04\n",
      "se agregó:  0.0 en:  3 65\n",
      "remake IN text_05\n",
      "se agregó:  1.0 en:  4 65\n",
      "trata NOT IN text_01\n",
      "se agregó:  0.0 en:  0 66\n",
      "trata NOT IN text_02\n",
      "se agregó:  0.0 en:  1 66\n",
      "trata NOT IN text_03\n",
      "se agregó:  0.0 en:  2 66\n",
      "trata NOT IN text_04\n",
      "se agregó:  0.0 en:  3 66\n",
      "trata IN text_05\n",
      "se agregó:  1.0 en:  4 66\n",
      "solamente NOT IN text_01\n",
      "se agregó:  0.0 en:  0 67\n",
      "solamente NOT IN text_02\n",
      "se agregó:  0.0 en:  1 67\n",
      "solamente NOT IN text_03\n",
      "se agregó:  0.0 en:  2 67\n",
      "solamente NOT IN text_04\n",
      "se agregó:  0.0 en:  3 67\n",
      "solamente IN text_05\n",
      "se agregó:  1.0 en:  4 67\n",
      "juegos NOT IN text_01\n",
      "se agregó:  0.0 en:  0 68\n",
      "juegos NOT IN text_02\n",
      "se agregó:  0.0 en:  1 68\n",
      "juegos NOT IN text_03\n",
      "se agregó:  0.0 en:  2 68\n",
      "juegos NOT IN text_04\n",
      "se agregó:  0.0 en:  3 68\n",
      "juegos IN text_05\n",
      "se agregó:  1.0 en:  4 68\n",
      "esperados NOT IN text_01\n",
      "se agregó:  0.0 en:  0 69\n",
      "esperados NOT IN text_02\n",
      "se agregó:  0.0 en:  1 69\n",
      "esperados NOT IN text_03\n",
      "se agregó:  0.0 en:  2 69\n",
      "esperados NOT IN text_04\n",
      "se agregó:  0.0 en:  3 69\n",
      "esperados IN text_05\n",
      "se agregó:  1.0 en:  4 69\n",
      "año NOT IN text_01\n",
      "se agregó:  0.0 en:  0 70\n",
      "año NOT IN text_02\n",
      "se agregó:  0.0 en:  1 70\n",
      "año NOT IN text_03\n",
      "se agregó:  0.0 en:  2 70\n",
      "año NOT IN text_04\n",
      "se agregó:  0.0 en:  3 70\n",
      "año IN text_05\n",
      "se agregó:  1.0 en:  4 70\n",
      "sino NOT IN text_01\n",
      "se agregó:  0.0 en:  0 71\n",
      "sino NOT IN text_02\n",
      "se agregó:  0.0 en:  1 71\n",
      "sino NOT IN text_03\n",
      "se agregó:  0.0 en:  2 71\n",
      "sino NOT IN text_04\n",
      "se agregó:  0.0 en:  3 71\n",
      "sino IN text_05\n",
      "se agregó:  1.0 en:  4 71\n",
      "bien NOT IN text_01\n",
      "se agregó:  0.0 en:  0 72\n",
      "bien NOT IN text_02\n",
      "se agregó:  0.0 en:  1 72\n",
      "bien NOT IN text_03\n",
      "se agregó:  0.0 en:  2 72\n",
      "bien NOT IN text_04\n",
      "se agregó:  0.0 en:  3 72\n",
      "bien IN text_05\n",
      "se agregó:  1.0 en:  4 72\n",
      "década NOT IN text_01\n",
      "se agregó:  0.0 en:  0 73\n",
      "década NOT IN text_02\n",
      "se agregó:  0.0 en:  1 73\n",
      "década NOT IN text_03\n",
      "se agregó:  0.0 en:  2 73\n",
      "década NOT IN text_04\n",
      "se agregó:  0.0 en:  3 73\n",
      "década IN text_05\n",
      "se agregó:  1.0 en:  4 73\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for word_termns in dicc_termns: #dicc_termns todos los términos\n",
    "#    print()\n",
    "    for word_texts in dicc_texts: #dicc_texts todos los textos\n",
    "#        print(\"EVALUAR:\", word_termns, \"EN: \", word_texts)\n",
    "        if(word_termns in dicc_texts[word_texts]): #si está\n",
    "            print(word_termns, \"IN\", word_texts)\n",
    "            \n",
    "            matrix[j, i] = dicc_termns[word_termns]\n",
    "            \n",
    "        elif(word_termns not in dicc_texts[word_texts]): # si no está\n",
    "            print(word_termns, \"NOT IN\", word_texts)\n",
    "            \n",
    "            matrix[j, i] = 0\n",
    "            \n",
    "            \n",
    "        print(\"se agregó: \", matrix[j,i], \"en: \", j, i)\n",
    "            \n",
    "        j = j + 1\n",
    "        \n",
    "    j = 0\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 3., 2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        2., 2., 2., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        2., 2., 2., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 74)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 3., 2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 2.,\n",
       "       2., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 2.,\n",
       "       2., 4., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-a1bc42962407>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "matrix[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3110855084191276"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t01_t02 = dot(matrix[0],matrix[1])/(norm(matrix[0])*norm(matrix[1]))\n",
    "df_cos_t01_t02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t01_t03 = dot(matrix[0],matrix[2])/(norm(matrix[0])*norm(matrix[2]))\n",
    "df_cos_t01_t03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t01_t04 = dot(matrix[0],matrix[3])/(norm(matrix[0])*norm(matrix[3]))\n",
    "df_cos_t01_t04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t01_t05 = dot(matrix[0],matrix[4])/(norm(matrix[0])*norm(matrix[4]))\n",
    "df_cos_t01_t05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t02_t03 = dot(matrix[1],matrix[2])/(norm(matrix[1])*norm(matrix[2]))\n",
    "df_cos_t02_t03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t02_t04 = dot(matrix[1],matrix[3])/(norm(matrix[1])*norm(matrix[3]))\n",
    "df_cos_t02_t04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13340746919301402"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t02_t05 = dot(matrix[1],matrix[4])/(norm(matrix[1])*norm(matrix[4]))\n",
    "df_cos_t02_t05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t03_t04 = dot(matrix[2],matrix[3])/(norm(matrix[2])*norm(matrix[3]))\n",
    "df_cos_t03_t04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t03_t05 = dot(matrix[2],matrix[4])/(norm(matrix[2])*norm(matrix[4]))\n",
    "df_cos_t03_t05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos_t04_t05 = dot(matrix[3],matrix[4])/(norm(matrix[3])*norm(matrix[4]))\n",
    "df_cos_t04_t05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
